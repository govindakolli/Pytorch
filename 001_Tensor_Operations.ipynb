{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKagIVRHlyfACdsEXLuHMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/govindakolli/Pytorch/blob/main/02_Tensor_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Tensor Operations**\n",
        "\n",
        "\n",
        "Tensor Operations are used to manipulate multi-dimensional arrays of numbers, i.e. tensors, that represent complex data.\n",
        "\n",
        "Here are some of the tensor operations :\n",
        "1. **Creating Tensors** : The *torch.tensor()* function creates a tensor from the given data.\n",
        "\n",
        "2. **Initialize Tensors**: Initialize tensors with various values and shapes using functions like *torch.tensor()*, *torch.zeros()*, and *torch.ones()*.\n",
        "\n",
        "3. **Random Tensors**: Generate tensors with random values using *torch.rand()*, *torch.randn()*, and *torch.randint()*.\n",
        "\n",
        "4. **Reshaping Tensors**: Transform tensor shapes using *view()* and *reshape()*.\n",
        "\n",
        "5. **Concatenating Tensors**: Combine multiple tensors with *torch.cat()* and *torch.stack()*.\n",
        "\n",
        "6. **Transpose and Permutation**: Reorder tensor dimensions using *torch.transpose()* and *torch.permute()*.\n",
        "\n",
        "7. **Converting to/from NumPy**: Seamlessly switch between PyTorch tensors and NumPy arrays using *tensor.numpy()* and *torch.from_numpy()*.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Before we begin, let's install and import PyTorch and see some functions with examples :\n"
      ],
      "metadata": {
        "id": "kxQqLbPUG9zr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yrBP61srrOMO"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch and Other modules\n",
        "import torch\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "zYshocdAJjDs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Creating tensors**\n",
        "\n",
        "The *torch.tensor()* function creates a tensor from the given data. It is one of the most fundamental ways to create a tensor in PyTorch. The function allows you to specify the data type* (dtype)*, device *(device)*, and other properties.\n",
        "\n",
        "\n",
        "*torch.tensor(data, dtype = None, device = None)* : Creates a tensor with specified data\n",
        "\n",
        "Examples:"
      ],
      "metadata": {
        "id": "A4BjC3V1J2Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a tensor from a list\n",
        "a = torch.tensor([[1, 2],[ 3, 4.]])\n",
        "print(a)\n",
        "#output = tensor([[1., 2.],[3., 4.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJnobQBNJyIJ",
        "outputId": "c0585636-a860-42f3-88f5-f26a2b0266f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function automatically converts the elements to a common data type (*float32* in this case) because one of the elements (*4.*) is a float. PyTorch promotes types to ensure consistency within the tensor."
      ],
      "metadata": {
        "id": "uf6wTmkFRvQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D tensor with float data\n",
        "\n",
        "b = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "print(b)\n",
        "#output =  tensor([[1., 2.],[3., 4.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MddJQVzMK3e4",
        "outputId": "020ea14b-9916-4e4a-ed2f-bee157cb31f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the *dtype* argument explicitly sets the data type to *float32*. This is useful when you want precise control over the data type for operations like floating-point calculations or GPU compatibility."
      ],
      "metadata": {
        "id": "58cmZlVVSNot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mixing data types  ; # Uncomment and run to see error\n",
        "\n",
        "# c = torch.tensor([[1, 2], [3, '4']])\n",
        "# Throws: TypeError: expected scalar type int but found str\n",
        "\n",
        "d = torch.tensor([[1, 2], [3, 4, 5]])\n",
        "#ValueError: expected sequence of length 2 at dim 1 (got 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "xPKPgDiRLAwg",
        "outputId": "c2ff7709-8311-4d1d-d372-0678a063049b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 2 at dim 1 (got 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3b1ff0851fed>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Throws: TypeError: expected scalar type int but found str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#ValueError: expected sequence of length 2 at dim 1 (got 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input list is not rectangular because the inner lists have different lengths ([1, 2] has length 2, while [3, 4, 5] has length 3). PyTorch requires all inner lists (or sequences) to have the same length to form a proper tensor.\n",
        "\n",
        "\n",
        "Use *torch.tensor(*) when you want to initialize tensors from Python lists or arrays with specific properties like data type or device. Ensure the input is rectangular (same size in all dimensions) and contains valid data types to avoid errors."
      ],
      "metadata": {
        "id": "NY1nKlJMSZtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Initializing Tensors**\n",
        "\n",
        "PyTorch provides various utility functions to initialize tensors with specific values, shapes, or patterns. Commonly used functions include *torch.zeros()*, *torch.ones()*, and others like *torch.eye()* for identity matrices or torch.rand() for random initialization.\n",
        "\n",
        "*torch.zeros(size)*: Create a tensor of zeros.\n",
        "\n",
        "*torch.ones(size)*: Create a tensor of ones.\n",
        "\n",
        "Examples:"
      ],
      "metadata": {
        "id": "IHIYpJtbMwjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 2x3 tensor of zeros\n",
        "\n",
        "zero_tensor = torch.zeros((2, 3))\n",
        "print(zero_tensor)\n",
        " # Output: tensor([[0., 0., 0.], [0., 0., 0.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx8wXjdqLrUN",
        "outputId": "4b731cee-1688-423c-9446-f13c16abe426"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The *torch.zeros()* function creates a tensor of shape *(2, 3)* filled with zeros. The default data type is *float32*. This is commonly used for initializing weights or placeholders for computations."
      ],
      "metadata": {
        "id": "ynZJXKveQjJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2x3 tensor of ones with int type\n",
        "\n",
        "one_tensor = torch.ones((2, 3), dtype=torch.int32)\n",
        "print(one_tensor)\n",
        " # Output: tensor([[1, 1, 1], [1, 1, 1]], dtype=torch.int32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D_-83jwNR_K",
        "outputId": "65b2791b-0de8-401f-b5f6-2d39cab11df5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.ones()* function creates a tensor of shape *(2, 3)* filled with ones. Here, the dtype argument specifies the tensor's data type as int32. This is useful for tasks requiring integer-based computations.\n",
        "\n"
      ],
      "metadata": {
        "id": "qBqJRFuwQ5gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and run to see error\n",
        "\n",
        "invalid_tensor = torch.zeros(-1, 3)  # Negative size\n",
        "# Throws: RuntimeError: shape should be of size greater than or equal to 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "H0Ks2uPlNbNM",
        "outputId": "f44ea084-ebc9-42eb-b30e-6b61a642719d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to create tensor with negative dimension -1: [-1, 3]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-aa35e8c37323>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Uncomment and run to see error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minvalid_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Negative size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Throws: RuntimeError: shape should be of size greater than or equal to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to create tensor with negative dimension -1: [-1, 3]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape argument cannot contain negative values (e.g., -2). Tensor dimensions must be non-negative integers. Ensure the shape you specify is valid and represents a real tensor.\n",
        "\n",
        "\n",
        "Functions like *torch.zeros()* and *torch.ones()* are essential for creating tensors with default values. They are useful for initializing model weights, placeholders, or constant tensors. Always verify the shape and data type to avoid errors during initialization."
      ],
      "metadata": {
        "id": "dfxXKLw_TVkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Random Tensors**\n",
        "\n",
        "\n",
        "PyTorch provides functions to initialize tensors with random values. These functions are commonly used to create random data for model initialization, simulations, or testing purposes.\n",
        "\n",
        "Common Random Tensor Functions :\n",
        "\n",
        "*torch.rand(size)* : Generates random numbers uniformly distributed in the range [0, 1).\n",
        "\n",
        "*torch.randn(size)* : Generates random numbers from a standard normal distribution (mean=0, std=1).\n",
        "\n",
        "\n",
        "Examples:"
      ],
      "metadata": {
        "id": "iJM9lAQYNuxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Random values [0, 1)\n",
        "rand_tensor = torch.rand((2, 2))\n",
        "print(rand_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUXlCULANl71",
        "outputId": "18fa6a7e-fa64-4c4d-dae9-0208f9a411a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8828, 0.0688],\n",
            "        [0.6320, 0.6521]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.rand()* function creates a tensor of shape *(2, 2)* filled with random values between 0 and 1. It is often used to generate test data or initialize weights in a model."
      ],
      "metadata": {
        "id": "fdT7IPUsUump"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Normally distributed random values\n",
        "randn_tensor = torch.randn((3, 2))\n",
        "print(randn_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL6jtwc-OLjR",
        "outputId": "384a3112-49f9-4028-e0cb-5bb944b3a1f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4864,  1.0187],\n",
            "        [-1.0318,  0.1341],\n",
            "        [ 1.9551, -1.4272]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.randn()* function creates a tensor of shape *(3, 2)* with random values from a normal distribution *(mean 0 and standard deviation 1)*. This is useful for testing models that assume normally distributed data."
      ],
      "metadata": {
        "id": "NLNEQL7kU_78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and run to see error\n",
        "\n",
        "invalid_rand = torch.rand(\"3\", 2)       # Non-integer size\n",
        "\n",
        "# Throws: TypeError: expected TensorOptions dtype, but got str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "inhDtblDONyo",
        "outputId": "207e738e-7e2e-44de-8b22-fa710edd450c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "rand() received an invalid combination of arguments - got (str, int), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-01549c721d5c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Uncomment and run to see error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minvalid_rand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# Non-integer size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Throws: TypeError: expected TensorOptions dtype, but got str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: rand() received an invalid combination of arguments - got (str, int), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first argument must be an integer specifying the size of the tensor. Passing a string (\"3\") instead of an integer results in a *TypeError*. Ensure all arguments are valid numerical types.\n",
        "\n",
        "\n",
        "Random tensor functions like *torch.rand()* and *torch.randn()* are essential for generating random data for testing, simulations, and model initialization. Always verify that the size argument is valid and consists of non-negative integers."
      ],
      "metadata": {
        "id": "OfcGqUBxVNsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Reshaping**\n",
        "\n",
        "Reshaping a tensor is often required to prepare it for certain operations, like feeding it into a model or processing it efficiently. PyTorch provides functions like *view()* and reshape() to change the shape of a tensor without altering its data.\n",
        "\n",
        "Key Difference:\n",
        "\n",
        "*tensor.view(shape)*: Reshapes the tensor while keeping its original memory layout. The new shape must be compatible with the original tensor.\n",
        "\n",
        "*tensor.reshape(shape)*: Similar to *view()*, but can create a copy of the tensor if needed, offering more flexibility.\n",
        "\n",
        "\n",
        "\n",
        "Examples:"
      ],
      "metadata": {
        "id": "KCYSnN_AOuPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(6)  # tensor([0, 1, 2, 3, 4, 5])\n",
        "reshaped = tensor.view(2, 3)  # Reshapes into 2 rows and 3 columns\n",
        "\n",
        "print(reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB8isBfoObmc",
        "outputId": "e454ddf9-4422-4277-a4b0-bb4349285177"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *view()* function reshapes the 1D tensor with 6 elements into a 2D tensor with shape *(2, 3)*. The total number of elements *(6)* remains the same."
      ],
      "metadata": {
        "id": "9Vmy5S-bWJJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(6)  # tensor([0, 1, 2, 3, 4, 5])\n",
        "reshaped = tensor.reshape(3, 2)  # Reshapes into 3 rows and 2 columns\n",
        "\n",
        "print(reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHyPdwOQWHTF",
        "outputId": "00e30748-0c20-465d-c5ef-982758712f1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *reshape(*) function changes the shape of the tensor into (*3, 2)*. Unlike *view()*, it creates a new tensor if the original memory layout is incompatible with the requested shape."
      ],
      "metadata": {
        "id": "UFrigMmNWfcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(6)  # tensor([0, 1, 2, 3, 4, 5])\n",
        "reshaped = tensor.view(4, 2)  # Mismatched shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "0xr_iKXcWY3M",
        "outputId": "55954a43-6cc7-487c-a894-c8b32f98d341"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[4, 2]' is invalid for input of size 6",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f02bc80aade8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# tensor([0, 1, 2, 3, 4, 5])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Mismatched shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 2]' is invalid for input of size 6"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *view()* function fails because the requested shape *(4, 2)* does not match the total number of elements in the original tensor *(6)*. The total number of elements must remain constant when reshaping.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Use *view()* or *reshape()* to change the shape of a tensor as needed for operations like feeding data into a neural network. Ensure the new shape is compatible with the original number of elements to avoid errors. Use *reshape()* when you need more flexibility and don't mind a potential copy.\n",
        "\n"
      ],
      "metadata": {
        "id": "TAy9GF8XWs4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Concatenating Tensors**\n",
        "\n",
        "Concatenation combines two or more tensors along a specified dimension. PyTorch provides functions like *torch.cat()* and *torch.stack()* for this purpose.\n",
        "\n",
        "Key Differences:\n",
        "\n",
        "*torch.cat(tensors, dim)*: Concatenates tensors along an existing dimension.\n",
        "\n",
        "*torch.stack(tensors, dim)*: Stacks tensors along a new dimension, increasing the rank of the tensor.\n",
        "\n",
        "Examples :"
      ],
      "metadata": {
        "id": "72v9NgmeXhLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor2 = torch.tensor([[5, 6], [7, 8]])\n",
        "concatenated = torch.cat((tensor1, tensor2), dim=0)  # Concatenate along rows\n",
        "\n",
        "print(concatenated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmVwazE8Wps3",
        "outputId": "a73d0256-1bf1-4e1d-e467-70f2cc745082"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.cat()* function concatenates *tensor1* and *tensor2* along *dim=0* (rows). The resulting tensor has the shape of *(4, 2)* because the rows are combined, but the columns remain same."
      ],
      "metadata": {
        "id": "kKL8StJPerir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor3 = torch.tensor([[6, 7], [8, 9]])\n",
        "stacked = torch.stack((tensor1, tensor3), dim= 0)  # stack along a new dimension\n",
        "\n",
        "print(stacked)\n",
        "print(stacked.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8JdhAQFcm4m",
        "outputId": "ff21e8d9-8aa9-430b-84ef-2f29d7181ca2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[6, 7],\n",
            "         [8, 9]]])\n",
            "torch.Size([2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.stack()* function adds a new dimension (*dim=0*) to stack the tensors. The resulting tensor has the shape of (2, 2, 2), where the new dimension corresponds to the number of tensors stacked."
      ],
      "metadata": {
        "id": "7h5nlViggKNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor4 = torch.tensor([[5, 6, 7],[8, 9, 10]])\n",
        "concat = torch.cat((tensor1, tensor4),dim = 1) #concat along columns\n",
        "\n",
        "print(concat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6YrLY33gBqg",
        "outputId": "89015f2c-be8d-48af-d0c9-6cb3ccd6bbdd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  5,  6,  7],\n",
            "        [ 3,  4,  8,  9, 10]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, *tensor1* and *tensor2* are concatenated along *dim=1* (columns). PyTorch allows this operation because the sizes along *dim=0* (rows) match, even though the number of columns differs. The resulting tensor has a shape of *(2, 5)* because the columns are combined."
      ],
      "metadata": {
        "id": "T-R0SVbLn-I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor2 = torch.tensor([5, 6])\n",
        "concatenated = torch.cat((tensor1, tensor2), dim=0)  # Attempt to concatenate along rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "TyxCmcEYkXR9",
        "outputId": "04df171d-f8d4-42ac-c9d9-1cd5b9f29e59"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Tensors must have same number of dimensions: got 2 and 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e102001fba92>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtensor2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconcatenated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Attempt to concatenate along rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.cat()* function fails here because the tensors have mismatched sizes in *dim=1* (columns). When concatenating along *dim=0* (rows), the column sizes must match, but *tensor1* has 2 columns while *tensor2* has only 1. This results in a *RuntimeError*.\n",
        "\n",
        "\n",
        "* torch.cat() requires matching sizes in all dimensions except the one being concatenated.\n",
        "\n",
        "* Ensure the dimensions align properly to avoid errors.\n",
        "\n",
        "* Carefully analyze the dimensions of tensors to determine the appropriate concatenation behavior."
      ],
      "metadata": {
        "id": "INqgq531oga1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Transpose and Permutation**\n",
        "\n",
        "Reordering dimensions of a tensor is a common operation in PyTorch, especially for tasks like reshaping data or aligning tensor dimensions for matrix operations. PyTorch provides two key functions for this purpose:\n",
        "\n",
        "*torch.transpose(input, dim0, dim1)* : Swaps two specified dimensions of the tensor.\n",
        "\n",
        "*torch.permute(dims)* : Rearranges all dimensions of the tensor based on the specified order.\n",
        "\n",
        "\n",
        "Key Differences:\n",
        "\n",
        "transpose is used for swapping two dimensions and is commonly applied to 2D or higher-order tensors.\n",
        "\n",
        "permute is more general and can reorder all dimensions of a tensor, making it useful for multi-dimensional tensors."
      ],
      "metadata": {
        "id": "SxT3z8vqpYqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "transposed = torch.transpose(tensor, 0, 1)  # Swaps rows and columns\n",
        "\n",
        "print(transposed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jpMo8XImP4i",
        "outputId": "8fa557b7-6f23-4d7b-a7e6-3a0a6d090458"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.transpose()* function swaps dimensions *0* (rows) and *1* (columns), effectively transposing the matrix."
      ],
      "metadata": {
        "id": "QQPq4Oxcqooy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.randn(2, 3, 4)  # Shape: (2, 3, 4)\n",
        "permuted = tensor.permute(2, 0, 1)  # Rearranges dimensions to (4, 2, 3)\n",
        "\n",
        "print(permuted.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHxOtuspqnRg",
        "outputId": "897249a3-5e3f-4c5a-b4c7-235c7f9d295b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *permute()* function rearranges the dimensions of the tensor according to the specified order *(2, 0, 1)*. This is especially useful for aligning data formats, such as switching from channel-first to channel-last."
      ],
      "metadata": {
        "id": "x6He0oErrAIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])  # 1D tensor\n",
        "transposed = torch.transpose(tensor, 0, 1)  # Attempt to transpose\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "bYqvz_5Aq8MJ",
        "outputId": "4befa238-17ce-4316-f653-c01aedc80ae4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a01f6b533a4a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 1D tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Attempt to transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.transpose()* function cannot be used on a 1D tensor because it requires at least two dimensions to swap. Ensure the tensor has enough dimensions before applying *transpose*."
      ],
      "metadata": {
        "id": "5Swn39dwrMVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.randn(2, 3, 4)  # Shape: (2, 3, 4)\n",
        "permuted = tensor.permute(0, 0, 1)  # Invalid dimension order\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "p6vQjM_erLTw",
        "outputId": "c5128804-9131-4b6d-eaee-81a22b599110"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "permute(): duplicate dims are not allowed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c19c68e7b02e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (2, 3, 4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpermuted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Invalid dimension order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: permute(): duplicate dims are not allowed."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *permute()* function fails because the dimensions specified must be unique. Repeating dimensions (e.g., (0, 0, 1)) results in an error. Ensure each dimension is included exactly once.\n",
        "\n",
        "\n",
        "* Use *transpose()* for simple dimension swaps (e.g., transposing matrices).\n",
        "\n",
        "\n",
        "* Use *permute()* for more complex reordering of dimensions in higher-dimensional tensors.\n",
        "\n",
        "\n",
        "* Always check the tensor's shape and ensure valid dimension indices to avoid runtime errors."
      ],
      "metadata": {
        "id": "5kLLCy6RrgDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Converting Tensors to/from NumPy**\n",
        "\n",
        "PyTorch provides seamless integration with NumPy, allowing tensors to be converted to and from NumPy arrays. This is particularly useful for interoperability between PyTorch and other libraries that use NumPy.\n",
        "\n",
        "Key Functions:\n",
        "\n",
        "*tensor.numpy()*: Converts a PyTorch tensor to a NumPy array.\n",
        "\n",
        "*torch.from_numpy(array)*: Converts a NumPy array to a PyTorch tensor.\n",
        "\n",
        "**Note**: These conversions share memory, meaning changes to one will reflect in the other unless explicitly copied."
      ],
      "metadata": {
        "id": "rW8mFx5VsmSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "numpy_array = tensor.numpy()\n",
        "\n",
        "print(numpy_array)\n",
        "print(type(numpy_array))\n",
        "\n",
        "print(tensor.dtype)\n",
        "print(numpy_array.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnVlZoaIrbGS",
        "outputId": "892585bd-16c3-4d65-aa60-5bacd4494f05"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3.]\n",
            "<class 'numpy.ndarray'>\n",
            "torch.float32\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.numpy()* method converts the PyTorch tensor to a NumPy array. The data type and values remain the same, but the object type changes."
      ],
      "metadata": {
        "id": "PCSAVfwrtFh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.array([4, 5, 6], dtype=np.float32)\n",
        "tensor = torch.from_numpy(numpy_array)\n",
        "\n",
        "print(tensor)\n",
        "print(type(tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWOG9rZStEX6",
        "outputId": "61a988fc-82a1-4d88-9a36-169cf805704a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 5., 6.])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *torch.from_numpy()* function converts a NumPy array to a PyTorch tensor. The conversion maintains a shared memory relationship, meaning changes to one affect the other."
      ],
      "metadata": {
        "id": "M2oG46NQt60W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3], device='cuda')  # Tensor on GPU\n",
        "numpy_array = tensor.numpy()\n",
        "\n",
        "#make sure to have NVIDIA GPU\n",
        "#TypeError: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "6e2knLzbt082",
        "outputId": "d3d3a959-017f-49dc-bb07-e6fb62882fbe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-cd926c7f59fa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Tensor on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnumpy_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#make sure to have NVIDIA GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#TypeError: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *numpy()* method works only for tensors stored on the CPU. If the tensor is on the GPU, you must first move it to the CPU using *.cpu()*."
      ],
      "metadata": {
        "id": "eoabyeI_uOCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "numpy_array = np.array([4, 5, 6], dtype=np.int64)\n",
        "numpy_array.flags.writeable = False  # Make the NumPy array read-only\n",
        "tensor = torch.from_numpy(numpy_array)\n",
        "tensor[0] = 10  # Attempt to modify the tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qykr88YiuGgp",
        "outputId": "9c7596a0-0fd5-4ab9-df6b-6e65d0ab05c7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-a08d7b5dd078>:3: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  tensor = torch.from_numpy(numpy_array)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The issue arises because *torch.from_numpy()* creates a tensor that shares memory with the NumPy array. When the NumPy array is read-only (non-writable), the corresponding PyTorch tensor cannot perform in-place modifications. PyTorch expects the underlying memory to be writable for tensors created from NumPy.\n",
        "\n",
        "To fix this issue, you can either:\n",
        "\n",
        " * 1. Create a writable NumPy array:"
      ],
      "metadata": {
        "id": "e7zbjdC7vSxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.array([4, 5, 6], dtype=np.int64)\n",
        "tensor = torch.from_numpy(numpy_array)\n",
        "tensor[0] = 10  # Works because the array is writable\n"
      ],
      "metadata": {
        "id": "_sPVkDG7uxYQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2. Clone the tensor to decouple it from the NumPy array:"
      ],
      "metadata": {
        "id": "1JiMC2WzvmQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.array([4, 5, 6], dtype=np.int64)\n",
        "numpy_array.flags.writeable = False  # Read-only array\n",
        "tensor = torch.from_numpy(numpy_array).clone()  # Clone to create a writable tensor\n",
        "tensor[0] = 10  # Now works without error\n"
      ],
      "metadata": {
        "id": "u0WhUagWviPx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shared Memory**: By default, PyTorch tensors and NumPy arrays share memory to enable efficient data interchange.\n",
        "\n",
        "\n",
        "**Read-only Arrays**: If the NumPy array is read-only, you must either make it writable or clone the tensor to perform modifications.\n",
        "\n",
        "Use *tensor.numpy()* to export PyTorch data for use in NumPy-based libraries.\n",
        "\n",
        "Use *torch.from_numpy()* to load NumPy data into PyTorch workflows.\n",
        "\n",
        "Ensure the tensor is on the CPU and the NumPy array is writable to avoid errors during conversion."
      ],
      "metadata": {
        "id": "BtFvSMHLvuG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Conclusion**\n",
        "\n",
        "In this notbook, we explored the most commonly used **tensor operations** in PyTorch, covering their functionality, practical examples, and common pitfalls. Here's a quick recap:\n",
        "\n",
        "1. **Creating Tensors** : The *torch.tensor()* function creates a tensor from the given data.\n",
        "\n",
        "2. **Initialize Tensors**: Initialize tensors with various values and shapes using functions like *torch.tensor()*, *torch.zeros()*, and *torch.ones()*.\n",
        "\n",
        "3. **Random Tensors**: Generate tensors with random values using *torch.rand()*, *torch.randn()*, and *torch.randint()*.\n",
        "\n",
        "4. **Reshaping Tensors**: Transform tensor shapes using *view()* and *reshape()*.\n",
        "\n",
        "5. **Concatenating Tensors**: Combine multiple tensors with *torch.cat()* and *torch.stack()*.\n",
        "\n",
        "6. **Transpose and Permutation**: Reorder tensor dimensions using *torch.transpose()* and *torch.permute()*.\n",
        "\n",
        "7. **Converting to/from NumPy**: Seamlessly switch between PyTorch tensors and NumPy arrays using *tensor.numpy()* and *torch.from_numpy()*.\n",
        "\n",
        "Each operation was demonstrated with working examples, including breaking cases to understand potential errors and how to handle them.\n",
        "\n",
        "**Where to Go Next**\n",
        "\n",
        "Now that you understand the basics of PyTorch tensor operations, here’s what you can do next:\n",
        "\n",
        "1. **Deep Dive into Advanced Tensor Operations** : Explore slicing, broadcasting, and element-wise operations.\n",
        "\n",
        "2. **Learn PyTorch's Autograd System**: Understand automatic differentiation and gradient computation.\n",
        "\n",
        "3. **Build Models**: Start applying these operations in neural network architectures.\n",
        "\n",
        "4. **Explore PyTorch Ecosystem**: Use libraries like torchvision for image processing or torchaudio for sound analysis.\n",
        "\n",
        "With practice and exploration, you’ll soon be adept at handling tensors in any deep learning project!"
      ],
      "metadata": {
        "id": "mWqniRnFsycM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference Links**\n",
        "1. Official documentation for tensor operations : https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "2. Introduction to PyTorch Tutorials : https://pytorch.org/tutorials/\n",
        "\n",
        "\n",
        "\n",
        "3. Deep Learning with PyTorch (Book by Eli Stevens et al.)\n",
        "\n",
        "4. Deep Learning with PyTorch - Zero to GANs by Jovian : https://jovian.com/learn/deep-learning-with-pytorch-zero-to-gans\n"
      ],
      "metadata": {
        "id": "lpuJ9AdJyYu8"
      }
    }
  ]
}
