{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR/i84V1rjthnyV7zura63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/govindakolli/Pytorch/blob/main/04_PyTorch_Custom_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. PyTorch Custom Datasets\n",
        "\n",
        "How do we get our own data into PyTorch?\n",
        "One of the ways to do so is via : custom datasets\n",
        "\n",
        "## Domain libraries\n",
        "\n",
        "Depending on what we are working on, vision, text, audio, recommendation, you'll want to look into each of the PyTorch domain libraries for existing data loading functions and customizable data loading functions\n",
        "\n"
      ],
      "metadata": {
        "id": "xpxjWlbj0uoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device-agnostic code\n"
      ],
      "metadata": {
        "id": "DaMj3UQ12FCP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8NNG7fY0e1v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "CxLYpTwY2hOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get Data\n",
        "Our dataset is a subset of the Food101 dataset.\n",
        "\n",
        "Food101 starts 101 different classes of food and 1000 images per class (750 training, 250 testing).\n",
        "\n",
        "Our dataset starts with 3 classes of food and only 10% of the images (~75 training, 25 testing).\n",
        "\n",
        "Why do this?\n",
        "\n",
        " Start small scale then increase.\n",
        "\n",
        "The whole point is to speed up how fast you can experiment.\n"
      ],
      "metadata": {
        "id": "6sjkcz6j_DlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to a data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and preapare it\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory already exists... skipping download\")\n",
        "else:\n",
        "  print(f\"Did not find {image_path} directory, creating one\")\n",
        "  image_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "# Download pizza, steak and sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\" ) as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza, steak and sushi data ...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak and sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\" Unzip pizza, steak and sushi data ...\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "ijTXMk5K2tFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Becoming one with data (Data preparation and data exploration)"
      ],
      "metadata": {
        "id": "poEcSWDveY7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"Walks through dir_path returning its contents.\"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}.\")"
      ],
      "metadata": {
        "id": "WJYDvdm4YWCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "zGrJTFcpe-NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "mLLrYummgIHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Visualizing and image\n",
        "\n",
        "Let's write some code to:\n",
        "1. Get all of the image paths.\n",
        "2. Pick a random image path using Python's random.choice()\n",
        "3. Get the image class name using `pathlib.Path.parent.stem`.\n",
        "4. Since we're working with images, let's open the image with Python's PIL.\n",
        "5. We'll then show the image and print metadata"
      ],
      "metadata": {
        "id": "ZLs2YhNYiDpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "# random.seed(42)\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# 2. Pick a random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "# print(random_image_path)\n",
        "\n",
        "# 3. Get image class from the path name\n",
        "image_class = random_image_path.parent.stem\n",
        "# print(image_class)\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path : {random_image_path}\")\n",
        "print(f\"Image class : { image_class}\")\n",
        "print(f\"Image height : {img.height}\")\n",
        "print(f\"Image width : {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "eF8zwDighiGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into array\n",
        "image_as_array = np.asarray(img)\n",
        "\n",
        "# Plot the image wwith matplotlib\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(image_as_array)\n",
        "plt.title(f\"Image class : {image_class} | Image shape : {image_as_array.shape} -> [H, W, Color channels]\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "g5Ra68UlkQ7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_as_array)"
      ],
      "metadata": {
        "id": "vYsAtHL44bns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transforming data\n",
        "\n",
        "Before we can use our image data with PyTorch:\n",
        "1. Turn our target data into tensors( in our case, numerical representations of data).\n",
        "2. Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`."
      ],
      "metadata": {
        "id": "1HqjDxUZ7abH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n"
      ],
      "metadata": {
        "id": "Pgt9mzz0499-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Transforming data with `torchvision.transdorms`"
      ],
      "metadata": {
        "id": "pJSgV50p8iLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize our image  to 64 x 64\n",
        "    transforms.Resize(size = (64, 64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    # Turn the image into a torch.tensor\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "kPJ2n6Ce8yLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img)\n"
      ],
      "metadata": {
        "id": "zGTArgYZ-fBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_images(image_paths: list , transform, n = 3, seed = 42):\n",
        "  \"\"\"\n",
        "  Selects random images from a path of images and loads/transforms them\n",
        "  then plots the original vs the transformed version.\n",
        "  \"\"\"\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "  random_image_paths = random.sample(image_paths, k = n)\n",
        "  for image_path in random_image_paths:\n",
        "    with Image.open(image_path) as f:\n",
        "      fig, ax = plt.subplots(nrows = 1, ncols = 2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[0].set_title(f\"Original \\n Size : {f.size}\")\n",
        "      ax[0].axis(False)\n",
        "\n",
        "      # Transform and plot\n",
        "      transformed_image = transform(f).permute(1, 2, 0) # note: we will need to change shape for matplotlib (C, H, W)-> (H, W, C)\n",
        "      ax[1].imshow(transformed_image)\n",
        "      ax[1].set_title(f\"Transformed \\n Size : {transformed_image.shape}\")\n",
        "      ax[1].axis(False)\n",
        "\n",
        "      fig.suptitle(f\"Class : {image_path.parent.stem}\", fontsize = 16)\n",
        "\n",
        "\n",
        "plot_transformed_images(image_paths= image_path_list, transform= data_transform, n= 3, seed= 128)"
      ],
      "metadata": {
        "id": "sEGsjUkX-_6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Option 1 : Loading image data using `torchvision.datasets.ImageFolder`"
      ],
      "metadata": {
        "id": "QyKEPGrEGdJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ImageFolder to  create dataset(s)\n",
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root = train_dir,\n",
        "                                  transform = data_transform, #  A transform for the data\n",
        "                                  target_transform = None) # A transform for the label/target\n",
        "\n",
        "test_data = datasets.ImageFolder(root = test_dir,\n",
        "                                 transform = data_transform)\n",
        "\n",
        "train_data, test_data"
      ],
      "metadata": {
        "id": "HY2bPd5gEF7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as list\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "cX9pFyGWO44A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "2NimstRHPVcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths of our dataset\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "Q2gIdmb-Pm4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.samples[0]"
      ],
      "metadata": {
        "id": "7BC1OjR_P3tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_data[0][0], train_data[0][1]\n",
        "print(f\"Image tensor :\\n {img}\")\n",
        "print(f\"Image shape : {img.shape}\")\n",
        "print(f\"Image datatype : {img.dtype}\")\n",
        "print(f\"Image label : {label}\")\n",
        "print(f\"Label datatype : {type(label)}\")"
      ],
      "metadata": {
        "id": "sagJrvPqP9rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearrange the order of dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "print(f\"Image shape after permute : {img_permute.shape}\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(img_permute)\n",
        "plt.title(f\"Image class : {class_names[label]}\", fontsize = 14)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "RukHb1vpQ1wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Turn loaded images into `DataLoader`'s"
      ],
      "metadata": {
        "id": "Wrj3vWMOTyOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.cpu_count()"
      ],
      "metadata": {
        "id": "qVih3WSQVAdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test datasets into DataLoader's\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "train_dataloader = DataLoader(dataset = train_data,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              num_workers = 1,#os.cpu_count(),\n",
        "                              shuffle = True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset = test_data,\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             num_workers = 1,\n",
        "                             shuffle = False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "5NmNPL_KQ2ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "geVux_iIVxjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "PNDlGETKV_PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "print(f\"Image shape: {img.shape} -> [BATCH_SIZE, H, W, Color channels]\")\n",
        "print(f\" Label shape : {label.shape}\")"
      ],
      "metadata": {
        "id": "xOXd5yZmWTPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Option 2 : Loading Image Data with a Custom `Dataset`\n",
        "\n",
        "1. Want to be able to load images from file\n",
        "2. Want to be able to get class names from the Dataset\n",
        "3. Want to be able to get classes as a dictionary from the Dataset\n",
        "\n",
        "Pros:\n",
        "\n",
        "* Can create a `Dataset` out of almost anything\n",
        "* Not limited to PyTorch pre-built `Dataset` functions\n",
        "\n",
        "Cons:\n",
        "* Even though you could create `Dataset` out of almost anything, it doesn't mean it will work...\n",
        "* Using a custom `Dataset`often results in us writing more code, which could be prone to errors or performance issues\n",
        "\n",
        "All custom datasets in PyTorch often subclass `torch.utils.data.Dataset`"
      ],
      "metadata": {
        "id": "nZxNAJQ6X92K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "5f9iRSP5W3CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "uX_jEBx3pbc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Creating a helper function to get class names\n",
        "\n",
        "We want a function to:\n",
        "1. Get the class names using `os.scandir()` to traverse a target directory(ideally the directory is in standard image classification folder)\n",
        "2. Raise an error if class names aren't found(if this happens there might be something wrong with the directory structure)\n",
        "3. Turn the class names into dict and a list and return them."
      ],
      "metadata": {
        "id": "H3qarM7Sre7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the path for tatget directory\n",
        "target_directory = train_dir\n",
        "print(f\"Target directiry : {target_directory}\")"
      ],
      "metadata": {
        "id": "As0joTnIrEBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names from the target directory\n",
        "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
        "class_names_found"
      ],
      "metadata": {
        "id": "Bow4XlaOulWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(os.scandir(target_directory))"
      ],
      "metadata": {
        "id": "rJKqGYs-vW5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "  \"\"\" Finds the classes folder names in a target directory.\"\"\"\n",
        "  # 1. Get the class names by scanning the target directory\n",
        "  classes = sorted([entry.name for entry in list(os.scandir(directory)) if entry.is_dir()])\n",
        "\n",
        "  # 2. Raise an error if class names could not be found\n",
        "  if not classes:\n",
        "    raise FileNotFoundError(f\"Couldn't find any classes in {directory}... please check the target directory\")\n",
        "\n",
        "  # 3. Create a directory of index labels(computers prefer numbers rather than strings as labels)\n",
        "  class_to_idx = {cls_name : idx for idx, cls_name in enumerate(classes)}\n",
        "  return classes, class_to_idx"
      ],
      "metadata": {
        "id": "woab745Mvchz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_classes(target_directory)"
      ],
      "metadata": {
        "id": "5WD6UDQ0xTJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Create a custom `Dataset` to replicate `ImageFolder`\n",
        "\n",
        "To create our own custom dataset, we want to:\n",
        "1. Subclass `torch.utils.data.Dataset`.\n",
        "2. Init our subclass with a target directory (the directory we'd like to get data from) as well as a transform if we'd like to transform our data.\n",
        "3. Create several attributes:\n",
        "  * paths - paths of our images\n",
        "  * transform - the transform we'd like to use\n",
        "  * classes - the list of the target classes\n",
        "  * class_to_idx - a dict of the target classes mapped to integer labels\n",
        "\n",
        "4. Create a function to `load_images()`, this function will open an image\n",
        "5. Overwrite the 1`__len()__` method to return the length of our dataset\n",
        "6. Overwrite the `__getitem()__` method to return a given sample when passed an index"
      ],
      "metadata": {
        "id": "51GRlmwOPqEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a custom dataset class\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 1. Subclass torch.utils.data.Dataset\n",
        "class ImageFolderCustom(Dataset):\n",
        "  # 2. Initialize our custom dataset\n",
        "  def __init__(self, targ_dir: str, transform = None):\n",
        "    super().__init__()\n",
        "\n",
        "    # 3. Create all class atributes\n",
        "    # Get all of the image paths\n",
        "    self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\"))\n",
        "    # Setup transforms\n",
        "    self.transform = transform\n",
        "    # Create classes and class_to_idx attributes\n",
        "    self.classes, self.class_to_idx = find_classes(targ_dir)\n",
        "\n",
        "  # 4. Create a function to load images\n",
        "  def load_image(self, index: int) -> Image.Image:\n",
        "    \"Opens an image via a path and returns it.\"\n",
        "    image_path = self.paths[index]\n",
        "    return Image.open(image_path)\n",
        "\n",
        "  # 5. Overwrite __len()__\n",
        "  def __len__(self) -> int:\n",
        "    \"Returns the total number of samples.\"\n",
        "    return len(self.paths)\n",
        "\n",
        "  # 6. Overwrite __getitem__() to return a particular sample\n",
        "  def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
        "    \"Returns one sample of data, data and label(X, y).\"\n",
        "    img = self.load_image(index)\n",
        "    class_name = self.paths[index].parent.name # expects path in format : data_folder/class_name/image.jpg\n",
        "    class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "    # Transform if necessary\n",
        "    if self.transform:\n",
        "      return self.transform(img),class_idx # return data, label (X, y)\n",
        "    else:\n",
        "      return img, class_idx # return untransformed image and label\n"
      ],
      "metadata": {
        "id": "cj7tsgDyxWnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Create a transform\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.Resize(size = (64,64)),\n",
        "                                      transforms.RandomHorizontalFlip(p = 0.5),\n",
        "                                      transforms.ToTensor()\n",
        "                                      ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                                      transforms.Resize(size = (64,64)),\n",
        "                                      transforms.ToTensor()\n",
        "                                      ])\n"
      ],
      "metadata": {
        "id": "anrhw9rkWhME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out ImageFolderCustom\n",
        "train_data_custom = ImageFolderCustom(targ_dir = train_dir,\n",
        "                                      transform = train_transform)\n",
        "\n",
        "test_data_custom = ImageFolderCustom(targ_dir = test_dir,\n",
        "                                     transform = test_transform)"
      ],
      "metadata": {
        "id": "kPlu0X2EgYhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom, test_data_custom"
      ],
      "metadata": {
        "id": "BEyIgiIdictZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(train_data_custom)"
      ],
      "metadata": {
        "id": "nb1l6CS8imJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data), len(test_data_custom)"
      ],
      "metadata": {
        "id": "WxK7Tlzxi24p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.classes"
      ],
      "metadata": {
        "id": "F7erDVWXjABM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.class_to_idx"
      ],
      "metadata": {
        "id": "Q36x_AcEjE33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for equality between original ImageFolder Dataset and ImageFolderCustom Dataset\n",
        "print(train_data_custom.classes == train_data.classes)\n",
        "print(test_data_custom.classes == test_data.classes)"
      ],
      "metadata": {
        "id": "S8jsiM_4jf84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Create a function to display random images\n",
        "\n",
        "1. Take in a `Dataset` and number of other parameters such as class names and how many images to visualize.\n",
        "2. To prevent the display getting out of hand, let's cap the number of images to see at 10.\n",
        "3. Set the random seed for reproducibility\n",
        "4. Get a list of random sample indexes from the target dataset.\n",
        "5. Setup a matplotlib plot.\n",
        "6. Loop through the random sample indexes and plot them with matplotlib.\n",
        "7. Make sure the dimensions of our images line up with matplotlib (HWC)"
      ],
      "metadata": {
        "id": "mp2_37Zuk9r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a function to take in a dataset\n",
        "def display_random_images(dataset : torch.utils.data.Dataset,\n",
        "                          classes : List[str] = None,\n",
        "                          n : int = 10,\n",
        "                          display_shape : bool = True,\n",
        "                          seed : int = None):\n",
        "  # 2. Adjust if n is too high\n",
        "  if n > 10:\n",
        "    n = 10\n",
        "    display_shape = False\n",
        "    print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
        "\n",
        "  # 3. set the seed\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "\n",
        "  # 4. Get random sample indexes\n",
        "  random_samples_idx = random.sample(range(len(dataset)), k = n)\n",
        "\n",
        "  # 5. setup plot\n",
        "  plt.figure(figsize = (16,8))\n",
        "\n",
        "\n",
        "  # 6. Loop through the random sample indexes and plot them with matplotlib.\n",
        "  for i, targ_sample in enumerate(random_samples_idx):\n",
        "    targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "    # 7. Adjust tensor dimensions for plotting\n",
        "    targ_image_adjust = targ_image.permute(1, 2, 0)\n",
        "\n",
        "    # Plot adjusted samples\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(targ_image_adjust)\n",
        "    plt.axis(\"off\")\n",
        "    if classes:\n",
        "      title = f\"class : {classes[targ_label]}\"\n",
        "      if display_shape:\n",
        "        title = title + f\"\\nshape : {targ_image_adjust.shape}\"\n",
        "    plt.title(title)\n"
      ],
      "metadata": {
        "id": "CShhyUBoj8_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random images from the ImageFolder created dataset\n",
        "display_random_images(train_data,\n",
        "                      n = 5,\n",
        "                      classes = class_names,\n",
        "                      seed = None)"
      ],
      "metadata": {
        "id": "nj_Uwkpoqodw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Display random images from the ImageFolderCustom dataset\n",
        "display_random_images(train_data_custom,\n",
        "                      n = 5,\n",
        "                      classes = class_names,\n",
        "                      seed = 42)"
      ],
      "metadata": {
        "id": "ilxsHXlRq_nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Turn custom loaded images into `DataLoader`'s"
      ],
      "metadata": {
        "id": "ROnhc2Ii4y0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "train_dataloader_custom =  DataLoader(dataset = train_data_custom,\n",
        "                                      batch_size = BATCH_SIZE,\n",
        "                                      num_workers = NUM_WORKERS,\n",
        "                                      shuffle = True)\n",
        "\n",
        "test_dataloader_custom =  DataLoader(dataset = test_data_custom,\n",
        "                                      batch_size = BATCH_SIZE,\n",
        "                                      num_workers = NUM_WORKERS,\n",
        "                                      shuffle = False)\n",
        "\n",
        "train_dataloader_custom, test_dataloader_custom"
      ],
      "metadata": {
        "id": "o5VzwwQLrG4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get image and label from custom dataloader\n",
        "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "\n",
        "#Print out the shapes\n",
        "img_custom.shape, label_custom.shape"
      ],
      "metadata": {
        "id": "QuI6kj8x5YiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Other forms of transforms (data augmentation)\n",
        "\n",
        "Data Augmentation is the process of artificially adding diversity to your training data.\n",
        "\n",
        "In case image data -> applying various image transformations to training images\n",
        "\n",
        "This practice hopefully results in a model that's more generalizable to unseen data.\n",
        "\n",
        "Let's take a look at one particular type of data augmentation used to train PyTorch vision models to state os the art levels..."
      ],
      "metadata": {
        "id": "p7eYLVnj8OZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at trivialaugment\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform  = transforms.Compose([\n",
        "                                       transforms.Resize(size = (224,224)),\n",
        "                                       transforms.TrivialAugmentWide(num_magnitude_bins = 31),\n",
        "                                       transforms.ToTensor()\n",
        "                                       ])\n",
        "\n",
        "test_tansform = transforms.Compose([\n",
        "                                    transforms.Resize(size = (224, 224)),\n",
        "                                    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "MMBlCmiN6_30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " image_path"
      ],
      "metadata": {
        "id": "AEy6gzzp8Lne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "image_path_list[:10]"
      ],
      "metadata": {
        "id": "Q0J9_2VgAJcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot random transformed images\n",
        "plot_transformed_images(\n",
        "    image_paths = image_path_list,\n",
        "    transform = train_transform,\n",
        "    n = 3,\n",
        "    seed = None\n",
        ")"
      ],
      "metadata": {
        "id": "C69MuJ5qAbEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model 0: TinyVGG without data augmentation\n",
        "\n"
      ],
      "metadata": {
        "id": "feWrry_yB1Og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Creating transforms and loading data for Model 0"
      ],
      "metadata": {
        "id": "b3MzmP-fCaX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create simple transfofrm\n",
        "simple_transform = transforms.Compose([\n",
        "                                       transforms.Resize(size = (64, 64)),\n",
        "                                       transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "0Nhrl93qA1mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and transform data\n",
        "from torchvision import datasets\n",
        "train_data_simple = datasets.ImageFolder(root = train_dir,\n",
        "                                         transform = simple_transform)\n",
        "test_data_simple = datasets.ImageFolder(root = test_dir,\n",
        "                                        transform = simple_transform)\n",
        "\n",
        "# 2. Turn the datasets into DataLoaders\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup batch size and number of workers\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# Create DataLoader's\n",
        "train_dataloaders_simple = DataLoader(dataset = train_data_simple,\n",
        "                                      batch_size = BATCH_SIZE,\n",
        "                                      num_workers = NUM_WORKERS,\n",
        "                                      shuffle = True)\n",
        "\n",
        "test_dataloaders_simple = DataLoader(dataset = test_data_simple,\n",
        "                                      batch_size = BATCH_SIZE,\n",
        "                                      num_workers = NUM_WORKERS,\n",
        "                                      shuffle = False)"
      ],
      "metadata": {
        "id": "2YHsgVquDBVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Create TinyVGG model class"
      ],
      "metadata": {
        "id": "fsNJP9IjLdDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = input_shape,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2,\n",
        "                     stride = 2 ) # default stride value is same as kernel_size\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2,\n",
        "                     stride = 2 ) # default stride value is same as kernel_size\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units * 13 *13,\n",
        "                  out_features = output_shape )\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(x.shape)\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    # print(x.shape)\n",
        "    return x\n",
        "    # return self.classifier(sel.conv_block_2(self.conv_block_1(x))) # benefits from operator fusion\n"
      ],
      "metadata": {
        "id": "p9C8s03NEw6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape = 3, # Number of color channels in our image data\n",
        "                   hidden_units = 10,\n",
        "                   output_shape = len(class_names)\n",
        "                   ).to(device)\n",
        "\n",
        "model_0"
      ],
      "metadata": {
        "id": "Afpsg4dRPeWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Try a forward pass on a single image ( to test the model )"
      ],
      "metadata": {
        "id": "qjZp3qcrZvC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single image batch\n",
        "image_batch, label_batch = next(iter(train_dataloaders_simple))\n",
        "image_batch.shape, label_batch.shape"
      ],
      "metadata": {
        "id": "RKAImsU2R1JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0(image_batch.to(device))"
      ],
      "metadata": {
        "id": "xkztL0VhaOaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Use `torchinfo` to get an idea of the shapes going through our model\n"
      ],
      "metadata": {
        "id": "wZlgozSndick"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torchinfo\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo"
      ],
      "metadata": {
        "id": "7w6GU1cudBpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model = model_0, input_size = (image_batch.shape))"
      ],
      "metadata": {
        "id": "tHloaAa6adDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5 Create train and test loop functions\n",
        "\n",
        "* `train_step()` - takes in model and dataloader and trains the model on the dataloader\n",
        "* `test_step()` - takes in model and dataloader and evaluates the model on the dataloader"
      ],
      "metadata": {
        "id": "6i9lG3bdgNaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train_step()\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader : torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device = device):\n",
        "  # Put the model in train mode\n",
        "  model_0.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through dataloader data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Send data to the target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1.Forward pass\n",
        "    y_pred = model_0(X)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate the accuracy metric\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim = 1), dim = 1)\n",
        "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust the metric to get average loss / accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "Ct4Dyikvc_W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module):\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "WNuIadCDXoD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s8u1aegMhkLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.6 Creating a `train()` function to combine `train_step()` and `test_step()`"
      ],
      "metadata": {
        "id": "Ajj58PlwFC_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "# 1. create a train function that takes in various model parameters + optimizer + dataloader + loss function\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5,\n",
        "          device = device):\n",
        "  # 2. Create empty results dictionary\n",
        "  results = {\"train_loss\" : [],\n",
        "             \"train_acc\" : [],\n",
        "             \"test_loss\" : [],\n",
        "             \"test_acc\" : []}\n",
        "\n",
        "  # 3. Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model = model,\n",
        "                                       dataloader = train_dataloader,\n",
        "                                       loss_fn = loss_fn,\n",
        "                                       optimizer = optimizer,\n",
        "                                       device = device)\n",
        "\n",
        "    test_loss, test_acc = test_step(model = model,\n",
        "                                    dataloader = test_dataloader,\n",
        "                                    loss_fn = loss_fn)\n",
        "    # 4. Print what's happenin'\n",
        "    print(f\"Epoch : {epoch} | Train loss : {train_loss: .4f}, Train acc : {train_acc:.2f}% | test loss : {test_loss: .4f} , test acc : {test_acc: .2f}%\")\n",
        "\n",
        "    # 5. Update results dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  # 6. return the filled results at the end of the epochs\n",
        "  return results"
      ],
      "metadata": {
        "id": "ONJpmRpuFB3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.7 Train and evaluate model 0"
      ],
      "metadata": {
        "id": "RIBcKPA7KPeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model_0 = TinyVGG(input_shape = 3, # number of color channels of our target image\n",
        "                  hidden_units = 10,\n",
        "                  output_shape = len(train_data.classes)).to(device)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model_0.parameters(), lr = 0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_0\n",
        "model_0_results = train(model = model_0,\n",
        "                         train_dataloader = train_dataloaders_simple,\n",
        "                         test_dataloader = test_dataloaders_simple,\n",
        "                         optimizer = optimizer,\n",
        "                         loss_fn = loss_fn,\n",
        "                         epochs = NUM_EPOCHS)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"\\nTotal trainig time : {(end_time - start_time):.3f}seconds\")"
      ],
      "metadata": {
        "id": "ay3eBUlQKOZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "_EoJGH51N0f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.8 Plot the loss curves of Model 0\n",
        "A **loss curve** is a way of tracking your model's progress over time.\n",
        "\n",
        "\n",
        "A guide - https://developers.google.com/machine-learning/crash-course/overfitting/interpreting-loss-curves"
      ],
      "metadata": {
        "id": "3lTz8HO9RFLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model_0_results keys\n",
        "model_0_results.keys()"
      ],
      "metadata": {
        "id": "G61kGtapRChw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "  \"\"\"Plots training curves of a results dictionary.\"\"\"\n",
        "  # Get the loss values of the results dictionary(training and test)\n",
        "  loss = results[\"train_loss\"]\n",
        "  test_loss = results[\"test_loss\"]\n",
        "\n",
        "  # Get the accuracy values of the results dictionary (training and testing)\n",
        "  accuracy = results[\"train_acc\"]\n",
        "  test_accuracy = results[\"test_acc\"]\n",
        "\n",
        "  # Figure out how many epochs there were\n",
        "  epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "  # Setup a plot\n",
        "  plt.figure(figsize=(15,7))\n",
        "\n",
        "  # Plot the loss\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, loss, label = \"train loss\")\n",
        "  plt.plot(epochs, test_loss, label = \"test loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot the accuracy\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs, accuracy, label = \"train accuracy\")\n",
        "  plt.plot(epochs, test_accuracy, label = \"test accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "noj74PHBTy4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_0_results)"
      ],
      "metadata": {
        "id": "kNZXUXiuXSh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. What should an ideal loss curve look like?\n",
        "\n",
        "A loss curve is one of the most helpful ways to troubleshoot a model."
      ],
      "metadata": {
        "id": "-fnfkEqXYy-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Model 1: TinyVGG with Data Augmentation"
      ],
      "metadata": {
        "id": "b7ctLQHgEEV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1 Create a transform with data augmentation"
      ],
      "metadata": {
        "id": "tWw8EPlBEUVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training transform with TrivialAugment\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform_trivial = transforms.Compose([\n",
        "                                              transforms.Resize(size = (64, 64)),\n",
        "                                              transforms.TrivialAugmentWide(num_magnitude_bins = 31),\n",
        "                                              transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform_simple = transforms.Compose([\n",
        "                                            transforms.Resize(size = (64, 64)),\n",
        "                                            transforms.ToTensor()\n",
        "])\n"
      ],
      "metadata": {
        "id": "3ZVgd-WJYGJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2 Create train and test `Dataset`s and `DataLoader`s with data augmentation"
      ],
      "metadata": {
        "id": "SsxmPGgXGW9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn image folders into Datasets\n",
        "from torchvision import datasets\n",
        "\n",
        "train_data_augmented = datasets.ImageFolder(root = train_dir,\n",
        "                                            transform = train_transform_trivial)\n",
        "\n",
        "test_data_simple = datasets.ImageFolder(root = test_dir,\n",
        "                                        transform = test_transform_simple)"
      ],
      "metadata": {
        "id": "temf3OMsGSKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our Datasets into DataLoaders\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup Hyperparamers\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 1#os.cpu_count()\n",
        "\n",
        "torch.manual_seed\n",
        "train_dataloader_augmented = DataLoader(dataset = train_data_augmented,\n",
        "                                        batch_size = BATCH_SIZE,\n",
        "                                        shuffle = True,\n",
        "                                        num_workers = NUM_WORKERS)\n",
        "\n",
        "test_dataloader_simple = DataLoader(dataset = test_data_simple,\n",
        "                                    batch_size = BATCH_SIZE,\n",
        "                                    shuffle = False,\n",
        "                                    num_workers = NUM_WORKERS)"
      ],
      "metadata": {
        "id": "qPFHCLk-HS8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.3  Construct and train Model 1\n"
      ],
      "metadata": {
        "id": "FMCdTA3zI-y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model and send it to target device\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = TinyVGG(input_shape = 3,\n",
        "                  hidden_units = 10,\n",
        "                  output_shape = len(train_data_augmented.classes)).to(device)\n",
        "\n",
        "\n",
        "model_1"
      ],
      "metadata": {
        "id": "R8iPmwiUIsew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "#set the number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Setup loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(params = model_1.parameters(),\n",
        "                             lr = 0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_1\n",
        "model_1_results = train(model = model_1,\n",
        "                        train_dataloader = train_dataloader_augmented,\n",
        "                        test_dataloader = test_dataloader_simple,\n",
        "                        optimizer = optimizer,\n",
        "                        loss_fn = loss_fn,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                        device = device)\n",
        "\n",
        "# End the time\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Total training time : {end_time - start_time: .3f} seconds\")"
      ],
      "metadata": {
        "id": "faoM3M7FKv1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.4 Plot the loss curves of model_1"
      ],
      "metadata": {
        "id": "tVr38zR0RBjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_1_results)"
      ],
      "metadata": {
        "id": "wAzVY7RQQeM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Compare model results\n",
        "\n",
        "After evaluating our modelling experiments on their own, it's important to compare them to each other.\n",
        "\n",
        "There are few different ways to do this:\n",
        "1. Hard copying (What we are doing)\n",
        "2. PyTorch + Tensorboard\n",
        "3. Weights & Biases\n",
        "4. MLFlow\n"
      ],
      "metadata": {
        "id": "EuwpAUSMVwa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "model_0_df = pd.DataFrame(model_0_results)\n",
        "model_1_df = pd.DataFrame(model_1_results)\n",
        "model_1_df"
      ],
      "metadata": {
        "id": "JGo-cnGERPzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a plot\n",
        "plt.figure(figsize = (15, 10))\n",
        "\n",
        "# Get the number of epochs\n",
        "epochs = range(len(model_0_df))\n",
        "\n",
        "# Plot train loss\n",
        "plt.subplot(2, 2, 1) # ( 2 rows, 2 cols, index 1)\n",
        "plt.plot(epochs, model_0_df['train_loss'], label = \"Model 0 train loss\")\n",
        "plt.plot(epochs, model_1_df['train_loss'], label = \"Model 1 train loss\")\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot train acc\n",
        "plt.subplot(2, 2, 3) # ( 2 rows, 2 cols, index 3)\n",
        "plt.plot(epochs, model_0_df['train_acc'], label = \"Model 0 train acc\")\n",
        "plt.plot(epochs, model_1_df['train_acc'], label = \"Model 1 train acc\")\n",
        "plt.title(\"Training accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test loss\n",
        "plt.subplot(2, 2, 2) # ( 2 rows, 2 cols, index 2)\n",
        "plt.plot(epochs, model_0_df['test_loss'], label = \"Model 0 test loss\")\n",
        "plt.plot(epochs, model_1_df['test_loss'], label = \"Model 1 test loss\")\n",
        "plt.title(\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test acc\n",
        "plt.subplot(2, 2, 4) # ( 2 rows, 2 cols, index 4)\n",
        "plt.plot(epochs, model_0_df['test_acc'], label = \"Model 0 test acc\")\n",
        "plt.plot(epochs, model_1_df['test_acc'], label = \"Model 1 test acc\")\n",
        "plt.title(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n"
      ],
      "metadata": {
        "id": "cwApNk6rXMPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Making a prediction on a custom image\n",
        "\n",
        "Although we've trained a model on custom data... how do you make a prediction on a sample/image that's not in either trainig or testing dataset."
      ],
      "metadata": {
        "id": "3fGVdnWYempG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download custom image\n",
        "import requests\n",
        "\n",
        "# Setup custom image path\n",
        "custom_image_path = data_path /\"04-pizza-dad.jpeg\"\n",
        "\n",
        "# Download the image if it doesn't already exist\n",
        "if not custom_image_path.is_file():\n",
        "  with open(custom_image_path, \"wb\") as f:\n",
        "    # When downloading from GitHub, need to use \"raw\" file link\n",
        "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
        "    print(f\"Downloading {custom_image_path}...\")\n",
        "    f.write(request.content)\n",
        "else:\n",
        "  print(f\"{custom_image_path} already exists, skipping download\")\n"
      ],
      "metadata": {
        "id": "bX-N2wQnZqbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.1 Loading in a custom image with PyTorch\n",
        "\n",
        "We have to make sure our custom image is in the same format as the data our model was trained on.\n",
        "\n",
        "* In tensor form with datatype (torch.float32)\n",
        "* Of shape 64x64x3\n",
        "* On the right device\n",
        "\n"
      ],
      "metadata": {
        "id": "iitjEtsUi4xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read in custom image using PIL to verify it's a valid image\n",
        "try:\n",
        "    img = Image.open(custom_image_path)\n",
        "    print(\"Image opened successfully with PIL.\")\n",
        "    # Optional: Display the image to visually confirm\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Custom Image loaded with PIL\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"Error opening or processing image with PIL: {e}\")\n",
        "    print(\"Please check if the downloaded file is a valid image.\")"
      ],
      "metadata": {
        "id": "zg7ve3-FmCoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# Read in custom image\n",
        "custom_image_uint8 = torchvision.io.read_image(custom_image_path)\n",
        "print(f\"Custom Image tensor : \\n{custom_image_uint8}\")\n",
        "print(f\"Custom image shape : {custom_image_uint8.shape}\")\n",
        "print(f\"Custom image datatype : {custom_image_uint8.dtype}\")"
      ],
      "metadata": {
        "id": "08X2sl9Uh6BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image_uint8.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "CHPt4lINucth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.2 Making a prediction on a custom image a trained PyTorch model"
      ],
      "metadata": {
        "id": "NfOO0WfKxLv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the custom image and convert to torch.float32\n",
        "custom_image = torchvision.io.read_image(custom_image_path).type(torch.float32)/255.\n",
        "custom_image"
      ],
      "metadata": {
        "id": "v24rSR6ExyB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "gWJpCEUny45R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to make a prediction on an image in uint8 format\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  model_1(custom_image.to(device))"
      ],
      "metadata": {
        "id": "gmOVJtOdygYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create transform pipeline to resize\n",
        "from torchvision import transforms\n",
        "custom_image_transform = transforms.Compose([\n",
        "                                             transforms.Resize(size = (64, 64))\n",
        "])\n",
        "\n",
        "# Transform target image\n",
        "custom_image_transformed = custom_image_transform(custom_image)\n",
        "\n",
        "# Print out the shapes\n",
        "print(custom_image_transformed.shape)"
      ],
      "metadata": {
        "id": "8JvFsF8uymUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image_transformed.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "OA3ZV7NO6GBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to make a prediction on an image in uint8 format\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  custom_image_pred = model_1(custom_image_transformed.to(device))"
      ],
      "metadata": {
        "id": "IjhFP4Ms6azl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_image_transformed.unsqueeze(dim=0).shape"
      ],
      "metadata": {
        "id": "g2eN1l5w7abp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to make a prediction on an image\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  custom_image_pred = model_1(custom_image_transformed.unsqueeze(dim=0).to(device))"
      ],
      "metadata": {
        "id": "V_lhGBVX7nYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_image_pred"
      ],
      "metadata": {
        "id": "CUND4zCQ65D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[custom_image_pred.argmax()]"
      ],
      "metadata": {
        "id": "esPr-5Gl7w1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: To make prediction on a custom image we had to:\n",
        "\n",
        "* Load the image and turn it into a tensor\n",
        "* Make sure the image was the same datatype as the model(torch.float32)\n",
        "* Make sure the image was the same shape as the data. The model was trained on (3, 64, 64) with a batch size...(1, 3, 64, 64)\n",
        "* Make sure the image was on the same device as our model  "
      ],
      "metadata": {
        "id": "ypzVIqEr8oUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert logits -> prediction probabities\n",
        "custom_image_pred_probs = torch.softmax(custom_image_pred, dim = 1)\n",
        "custom_image_pred_probs"
      ],
      "metadata": {
        "id": "tdFtXzGz7QP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities -> prediction labels\n",
        "custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=1).cpu()\n",
        "custom_image_pred_label"
      ],
      "metadata": {
        "id": "0RphW2d1_xCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[custom_image_pred_label]"
      ],
      "metadata": {
        "id": "31j2gzDYAQXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3 Putting custom image prediction together: building a function\n",
        "\n",
        "Ideal outcome:\n",
        "\n",
        "A function where we pass an image path to and have our model predict on that image and plot the image + prediction"
      ],
      "metadata": {
        "id": "HDOtZ0s9Aq_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot_image(model: torch.nn.Module,\n",
        "                        image_path: str,\n",
        "                        class_names: List[str] = None,\n",
        "                        transform=None,\n",
        "                        device: torch.device = device):\n",
        "    \"\"\"Makes a prediction on a target image and plots the image with its prediction.\"\"\"\n",
        "\n",
        "    # 1. Load in image and convert the tensor values to float32\n",
        "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
        "\n",
        "    # 2. Divide the image pixel values by 255 to get them between [0, 1]\n",
        "    target_image = target_image / 255.\n",
        "\n",
        "    # 3. Transform if necessary\n",
        "    if transform:\n",
        "        target_image = transform(target_image)\n",
        "\n",
        "    # 4. Make sure the model is on the target device\n",
        "    model.to(device)\n",
        "\n",
        "    # 5. Turn on model evaluation mode and inference mode\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Add an extra dimension to the image\n",
        "        target_image = target_image.unsqueeze(dim=0)\n",
        "\n",
        "        # Make a prediction on image with an extra dimension and send it to the target device\n",
        "        target_image_pred = model(target_image.to(device))\n",
        "\n",
        "    # 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
        "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "\n",
        "    # 7. Convert prediction probabilities -> prediction labels\n",
        "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "\n",
        "    # 8. Plot the image alongside the prediction and prediction probability\n",
        "    plt.imshow(target_image.squeeze().permute(1, 2, 0)) # make sure it's the right size for matplotlib\n",
        "    if class_names:\n",
        "        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "    else:\n",
        "        title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "    plt.title(title)\n",
        "    plt.axis(False);"
      ],
      "metadata": {
        "id": "WO03w8M3AXfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pred on our custom image\n",
        "pred_and_plot_image(model=model_1,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "weGnZV0gC_HS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}