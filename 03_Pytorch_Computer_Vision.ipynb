{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/govindakolli/Pytorch/blob/main/03_Pytorch_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Computer Vision"
      ],
      "metadata": {
        "id": "voukwQSqwNNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Computer vision libraries in PyTorch\n",
        "\n",
        "* [torchvision](https://docs.pytorch.org/vision/stable/index.html) - base domain library for computer vision\n",
        "\n",
        "* `torchvision.datasets` - get datasets and data loading functions for computer vision here\n",
        "\n",
        "* `torchvision.models` - get pretrained computer vision models that you can leverage for your own problems\n",
        "\n",
        "* `torchvision.transforms` - functions for manipulating your vision data(images) to be suitable for use with an ML model\n",
        "\n",
        "* `torch.utils.data.dataset` - Base dataset class for PyTorch\n",
        "\n",
        "* `torch.utils.data.DataLoader` - Create a Python iterable over  a dataset"
      ],
      "metadata": {
        "id": "djW8CWLFwSNN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0J0FKj7v-7u"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting a Dataset\n",
        "\n",
        "The dataset we'll be using is FashionMNIST from torchvision.datasets"
      ],
      "metadata": {
        "id": "Aixjpwii3qk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root = 'data', # Where to download data\n",
        "    train = True, # Do we want the training dataset?\n",
        "    download = True, # download dataset?\n",
        "    transform = ToTensor(), # # How do we want to transform the data\n",
        "    target_transform = None  # How do we want to transform the labels/targets\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        "    target_transform = None\n",
        ")"
      ],
      "metadata": {
        "id": "9DUKUSaf2LfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "d2bCbga-5a1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the first training example\n",
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "qk1mOgSD6PZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "jE4FjpaD6ZmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "mTbAC-s76nTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "kS3OodoW619w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Check the Input and Output shapes of the data"
      ],
      "metadata": {
        "id": "UmowzfRN73IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape our image\n",
        "image.shape, class_names[label]"
      ],
      "metadata": {
        "id": "jgFbn_Un7Jel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Visualizing our data"
      ],
      "metadata": {
        "id": "4GwL7lUQF_x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Image shape : {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(class_names[label])"
      ],
      "metadata": {
        "id": "OztrMHVc7T9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(),cmap=\"grey\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "k6hP3NaiGXuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_idx = torch.randint(0,len(train_data), size =[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows,cols,i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"grey\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "GcSOxoT3G7z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "avosreyIZvgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare DataLoader\n",
        "\n",
        "Right now, our data is in the form of PyTorch Datasets.\n",
        "\n",
        "DataLoader turns our dataset into a Python iterable\n",
        "\n",
        "More specifically, we want turn our data into batches(or mini-batches).\n",
        "\n",
        "Why would we do this?\n",
        "\n",
        "\n",
        "Because it's more computationally efficient:\n",
        "In an ideal world you could do the forward pass and backward pass across all of your data at once.\n",
        "But once you start using really large datasets, unless you've got infinite computing power, it's easier to break them up into batches.\n",
        "\n",
        "It also gives your model more opportunities to improve.\n",
        "With mini-batches (small portions of the data), gradient descent is performed more often per epoch (once per mini-batch rather than once per epoch).\n",
        "\n",
        "What's a good batch size?\n",
        "\n",
        "32 is a good place to start for a fair amount of problems.\n",
        "But since this is a value you can set (a hyperparameter) you can try all different kinds of values, though generally powers of 2 are used most often (e.g. 32, 64, 128, 256, 512)."
      ],
      "metadata": {
        "id": "6rxXcZO0Zzcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " from torch.utils.data import DataLoader\n",
        "\n",
        " # Set up batch size hyperparameter\n",
        " BATCH_SIZE =32\n",
        "\n",
        " # Turn datasets into iterables\n",
        "train_dataloader = DataLoader(dataset = train_data,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              shuffle = True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset = test_data,\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             shuffle = False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "E4UtAlNjZzB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "T89ldCzrHoKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "id": "hMXapNJCfLB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size = [1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"image shape : {img.shape}\")\n",
        "print(f\"label :{label}\")"
      ],
      "metadata": {
        "id": "oSyHVawwfK_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model 0: Build a baseline model\n",
        "\n",
        "Start with a simple model"
      ],
      "metadata": {
        "id": "UNxhpXfKr7YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]\n",
        "\n",
        "# Flatten the sample\n",
        "output = flatten_model(x)\n",
        "\n",
        "# Print out what happened\n",
        "print(f\"Shape before flattening : {x.shape}\")\n",
        "print(f\"Shape after flattening : {output.shape}\")"
      ],
      "metadata": {
        "id": "ZeAonTXQfKj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = input_shape, out_features = hidden_units),\n",
        "        nn.Linear(in_features = hidden_units, out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "A6c8V0HhuUJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set up  model with input parameters\n",
        "model_0 = FashionMNISTModelV0(\n",
        "    input_shape = 784,# 28*28 = 784\n",
        "    hidden_units = 10, # how many units in hidden layer\n",
        "    output_shape = len(class_names) # one for every class\n",
        ").to(\"cpu\")\n",
        "\n",
        "model_0"
      ],
      "metadata": {
        "id": "L0geTQtBuUFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.rand([1, 1, 28, 28])\n",
        "model_0(dummy_x)"
      ],
      "metadata": {
        "id": "OuiWB9q3uUCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Setup loss, optimizer and evaluation metrics\n",
        "\n",
        "* Loss function - since we are working with multi-class data, our loss function will be `nn.CrossEntropyLoss()\n",
        "* Optimizer - SGD\n",
        "* Evaluation metrics - Classification -> accuracy"
      ],
      "metadata": {
        "id": "ixSoL0WH9VSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from PyTorch repo\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"hepler_functions.py is existed. Skipping download\")\n",
        "else:\n",
        "  print(\"Downloading hepler_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "afvV4X29uTvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import accuracy metric\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Setip optimizer\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "1fN-ioF8AneU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Creating a function to time our experiments\n",
        "\n",
        "Two of main things we need to track are:\n",
        "1. Model's performance (loss and accuracy values etc)\n",
        "2. How fast it runs"
      ],
      "metadata": {
        "id": "afV0S4aaCmw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start : float,\n",
        "                     end : float,\n",
        "                     device : torch.device = None):\n",
        "  \"\"\" Prints difference between start and end time\"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device} : {total_time : .3f} seconds \")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "yg-4gQsXAnbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timer()\n",
        "# Some code\n",
        "end_time = timer()\n",
        "\n",
        "print_train_time(start = start_time, end = end_time, device = \"cpu\")"
      ],
      "metadata": {
        "id": "JDHLSpkwAnXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Creating a training loop and training a model on batches of data\n",
        "\n",
        "1. Loop through epochs.\n",
        "2. Loop through training batches, perform training steps, calculate the train loss per batch.\n",
        "3. Loop through testing batches, perform testing steps, calculate the test loss per batch.\n",
        "4. Print out waht's happening.\n",
        "5. Time it all."
      ],
      "metadata": {
        "id": "tVQdwnorFqCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Set the numberof epochs\n",
        "epochs = 3\n",
        "\n",
        "# Create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch : {epoch}\\n----\")\n",
        "  ### Training\n",
        "  train_loss = 0\n",
        "\n",
        "  # Add a loop to loop through the training batches\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_0(X)\n",
        "\n",
        "    # 2. Calculate the loss (per batch)\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    train_loss += loss # accumulate train loss\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out what's happening\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Divide total train loss by length of train dataloader\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  ### Testing\n",
        "  test_loss, test_acc = 0,0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      # 1. Forward pass\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      # 2. calculate the loss (accumulatively)\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true = y_test, y_pred = test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Calculate the accuracy average per batch\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"\\nTrain loss : {train_loss:.4f} | Test loss : {test_loss:.4f}, Test Acc : {test_acc:.2f}%\")\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start = train_time_start_on_cpu, end = train_time_end_on_cpu, device=str(next(model_0.parameters()).device))\n"
      ],
      "metadata": {
        "id": "bTN9d65xE2m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Make predictions and get Model 0 results"
      ],
      "metadata": {
        "id": "d12y-rHUV8ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "  \"\"\"Returns a dictionary containing the results of the model predicting on data_loader.\"\"\"\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in tqdm(data_loader):\n",
        "      # Make our data device agnostic\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      # Make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Accumulate the loss and acc values per batch\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true = y,\n",
        "                         y_pred = y_pred.argmax(dim=1))\n",
        "\n",
        "    # Scale loss and acc to find the average loss/acc per batch\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"model_name\": model.__class__.__name__, # only works when model was created with class\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model = model_0,\n",
        "                             data_loader = test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn = accuracy_fn)\n",
        "\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "otCCHtNgE2a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Setup device agnostic-code (for using a GPU if there is one)"
      ],
      "metadata": {
        "id": "Jc1T85-UtmHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "En_Hyh2Zsh_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "v3OBM8VcuVib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model 1: Building a better model with non-linearity"
      ],
      "metadata": {
        "id": "-aOw0mMaV-Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model with non-linearity\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = input_shape, out_features = hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features = hidden_units, out_features = output_shape),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "f79cGDDrupa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of model_1\n",
        "torch.manual_seed(42)\n",
        "model_1 = FashionMNISTModelV1(input_shape = 784,\n",
        "                              hidden_units = 10,\n",
        "                              output_shape = len(class_names)).to(device)\n",
        "\n",
        "model_1"
      ],
      "metadata": {
        "id": "IDK2idZpWKVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Setup loss, optimizer and evaluation metrics"
      ],
      "metadata": {
        "id": "YsAAxfg9X2JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_1.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "06GO90-jXIdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Functioning training and evaluation/testing loops\n",
        "\n",
        "Let's create function for :    \n",
        "* training loop - `train_steo()`\n",
        "\n",
        "* test loop - `test_step()`"
      ],
      "metadata": {
        "id": "-C89TcQ3eg3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "  \"\"\"Performs training step on model trying to learn on data loader\"\"\"\n",
        "  ### Training\n",
        "  train_loss, train_acc = 0,0\n",
        "\n",
        "  # Put model into training mode\n",
        "  model.train()\n",
        "\n",
        "  # Add a loop to loop through the training batches\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "\n",
        "    # Put data into target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # 2. Calculate the loss and accuracy (per batch)\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    train_loss += loss # accumulate train loss\n",
        "    train_acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim = 1))\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "  # Divide total train loss  and accuracy by length of train dataloader\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"Train loss : {train_loss:.5f} | Train acc : {train_acc: .2f}%\")"
      ],
      "metadata": {
        "id": "IpMTT-yvYYvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "  \"\"\"Performs testing step on trained model on data loader\"\"\"\\\n",
        "  ### Testing\n",
        "  test_loss, test_acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in data_loader:\n",
        "\n",
        "      # Send data to the target device\n",
        "      X_test,y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      test_pred = model(X_test)\n",
        "\n",
        "      # 2. calculate the loss (accumulatively)\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true = y_test, y_pred = test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(data_loader)\n",
        "\n",
        "    # Calculate the accuracy average per batch\n",
        "    test_acc /= len(data_loader)\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"\\nTest loss : {test_loss:.4f}, Test Acc : {test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "TUTvxbxYis3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "# Set the numberof epochs\n",
        "epochs = 3\n",
        "\n",
        "# Create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch : {epoch}\\n----\")\n",
        "  train_step(model = model_1,\n",
        "             data_loader = train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer = optimizer,\n",
        "             accuracy_fn = accuracy_fn,\n",
        "             device = device)\n",
        "\n",
        "  test_step(model = model_1,\n",
        "             data_loader = train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             accuracy_fn = accuracy_fn,\n",
        "             device = device)\n",
        "\n",
        "\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start = train_time_start_on_gpu,\n",
        "                                            end =train_time_end_on_gpu,\n",
        "                                            device = device)"
      ],
      "metadata": {
        "id": "kLX65fW4kVwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Sometimes, depending on your data/hardware you might find that your model trains faster on CPU than GPU.\n",
        "\n",
        "* Why is this?\n",
        "\n",
        "1. It could be that the overhead for copying data/model to and from the GPU outweights the compute benefits offered by the GPU.\n",
        "2. The hardware you are using has a better CPU in terms of compute capability than the GPU.\n",
        "\n",
        "For more  - https://horace.io/brrr_intro.html"
      ],
      "metadata": {
        "id": "VOubbK8Wnc3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "YuoCRsCOmo31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_time_model_0"
      ],
      "metadata": {
        "id": "9Z9hOqASpNCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model_1 results dictionary\n",
        "model_1_results = eval_model(model = model_1,\n",
        "                             data_loader = test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn = accuracy_fn)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "Nm29QgO6pTbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model 2 : Building a Convolutional Neural Network (CNN)\n",
        "\n",
        "CNN's are also known as ConvNets.\n",
        "\n",
        "for more visual CNNs - https://poloclub.github.io/cnn-explainer/"
      ],
      "metadata": {
        "id": "934eTb8GtVYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional Nueral Network\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "  \"\"\"Model architecture that replicates the TinyVGG\n",
        "  model from CNN Explainer website.\"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = input_shape, out_channels = hidden_units, kernel_size = 3, stride = 1, padding = 1), # Values we can set ourselves in NNs are called hyperparameters\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units, out_channels = hidden_units, kernel_size = 3, stride = 1, padding =1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = hidden_units, out_channels = hidden_units, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units, out_channels = hidden_units, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units * 7 * 7, # there s trick to calculating this ...\n",
        "                  out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(x.shape)\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "iqF8V8RNpywh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "eCz308322PHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_2 = FashionMNISTModelV2(input_shape = 1,\n",
        "                              hidden_units = 10,\n",
        "                              output_shape = len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "O2iFBCem2Q2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass an image through through it\n",
        "#model_2(image).to(device)\n",
        "model_2(image.unsqueeze(dim=0)).to(device)"
      ],
      "metadata": {
        "id": "Uj7K9DCzZmva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Stepping through `nn.Conv2d`"
      ],
      "metadata": {
        "id": "FQ0ROZWZ33pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a batch of images\n",
        "images = torch.randn(size = (32, 3, 64, 64))\n",
        "test_image = images[0]\n",
        "\n",
        "print(f\"Shape of the image batch: {images.shape}\")\n",
        "print(f\"Single image shape: {test_image.shape}\")\n",
        "print(f\"test image : {test_image}\")"
      ],
      "metadata": {
        "id": "YCXRp0YL2po2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a single conv2d layer\n",
        "conv_layer = nn.Conv2d(in_channels = 3,\n",
        "                       out_channels = 10,\n",
        "                       kernel_size = (3,3),\n",
        "                       stride = 1,\n",
        "                       padding = 1)\n",
        "# Pass the data through the convolutional layer\n",
        "conv_output = conv_layer(test_image.unsqueeze(dim=0)) # Unsqueeze is optional\n",
        "conv_output.shape"
      ],
      "metadata": {
        "id": "sCXa10cJ4zXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Stepping through `nn.MaxPool2d()`"
      ],
      "metadata": {
        "id": "SUXYoJaUSe2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image.shape"
      ],
      "metadata": {
        "id": "GhkkbPd9-fKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out original image shape without unsqueezed dimension\n",
        "print(f\"Test image shape : {test_image.shape}\")\n",
        "print(f\"Test image unsqueezed shape : {test_image.unsqueeze(dim=0).shape}\")\n",
        "\n",
        "# Create a sample nn.MaxPool2d layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "#pass data through just the conv_layer\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print(f\"Shape after going through conv layer : {test_image_through_conv.shape}\")\n",
        "\n",
        "# Pass data through the max poop layer\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"Shape after going through max pool layer : {test_image_through_conv_and_max_pool.shape}\")"
      ],
      "metadata": {
        "id": "LYHFjAIUTIc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Setup loss function and optimizer for `model_2`"
      ],
      "metadata": {
        "id": "u9r4En5ibTBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up loss function and accuracy metrics\n",
        "from helper_functions import accuracy_fn\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_2.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "4S9OhFHAVwia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Training and testing our `model_2` using our training and testing functions"
      ],
      "metadata": {
        "id": "WNQCMpAmckS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "# Set the numberof epochs\n",
        "epochs = 3\n",
        "\n",
        "# Create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch : {epoch}\\n----\")\n",
        "  train_step(model = model_2,\n",
        "             data_loader = train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer = optimizer,\n",
        "             accuracy_fn = accuracy_fn,\n",
        "             device = device)\n",
        "\n",
        "  test_step(model = model_2,\n",
        "             data_loader = train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             accuracy_fn = accuracy_fn,\n",
        "             device = device)\n",
        "\n",
        "\n",
        "train_time_end_model_2 = timer()\n",
        "total_train_time_model_2 = print_train_time(start = train_time_start_on_gpu,\n",
        "                                            end =train_time_end_on_gpu,\n",
        "                                            device = device)"
      ],
      "metadata": {
        "id": "JE6Ss3NqcBkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model_2 results\n",
        "model_2_results = eval_model(model = model_2,\n",
        "                             data_loader = test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn = accuracy_fn\n",
        "                             )\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "wPQwl7Y2dbtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Compare model results and training time"
      ],
      "metadata": {
        "id": "NZ0KR8aCfIUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results,\n",
        "                                model_1_results,\n",
        "                                model_2_results])\n",
        "compare_results"
      ],
      "metadata": {
        "id": "32O6Azxkeubn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
        "                                     total_train_time_model_1,\n",
        "                                     total_train_time_model_2]\n",
        "\n",
        "#compare_results = compare_results.drop([\"train9ng_time\"],axis=1)"
      ],
      "metadata": {
        "id": "Q9bcxDalfiLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results"
      ],
      "metadata": {
        "id": "d5Wad9GIgKcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VIsualize our model results\n",
        "compare_results.set_index(\"model_name\")['model_acc'].plot(kind=\"barh\")\n",
        "plt.xlabel(\"accuracy (%)\")\n",
        "plt.ylabel(\"model\")"
      ],
      "metadata": {
        "id": "aUYEYl6ngrc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Make and evaluate random predictions using our best model"
      ],
      "metadata": {
        "id": "MCheytlJl0Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model: torch.nn.Module,\n",
        "                     data: list,\n",
        "                     device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      # Prepare the sample (add a batch dimension and pass to target device)\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "\n",
        "      # Forward pass (model outputs are raw logits)\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      # Get prediction probability\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(),dim=0)\n",
        "\n",
        "      # Get pred_prob off the gpu for further calculations\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "  # Stack the pred_probs to turn list into a tensor\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "NhviwP3xh5FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "test_sample = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_sample.append(sample)\n",
        "  test_labels.append(label)"
      ],
      "metadata": {
        "id": "gHuCGRyznhJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample[0].shape"
      ],
      "metadata": {
        "id": "7OtbEjjvovhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_sample[0].squeeze(dim=0), cmap = \"gray\")\n",
        "plt.title(class_names[test_labels[0]])"
      ],
      "metadata": {
        "id": "7iKcHCqeo0iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "pred_probs = make_predictions(model = model_2,\n",
        "                              data = test_sample)\n",
        "\n",
        "# View first two prediction probabilities\n",
        "pred_probs[:2]\n"
      ],
      "metadata": {
        "id": "d4LQcfVJo78-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COnvert prediction probabilities to labels\n",
        "pred_classes = torch.argmax(pred_probs,dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "HH-0NgzYp3D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "Cu8wfpSlqPpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize = (9,9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_sample):\n",
        "  # Create subplot\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  #Plot the target image\n",
        "  plt.imshow(sample.squeeze(dim=0), cmap=\"gray\")\n",
        "\n",
        "  # Find the prediction ( in text form e.g Sandal )\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # Get the truth tabel in text form\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # Create a title for the plot\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # Check for equality between pred and truth and change color of title text\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize = 10, c=\"g\")\n",
        "  else:\n",
        "    plt.title(title_text, fontsize = 10, c=\"r\")\n",
        "\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "8msugBvYqS2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Making a confusion matrix for further prediction evaluation\n",
        "\n",
        "1. Make predictions with our trained model on the test dataset\n",
        "2. Make a confusion matrix `torchmetrics.ConfusionMatrix`\n",
        "3. Plot the confusion matrix using `mlxtend.plotting.plot_confusion_matrix() - https://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/"
      ],
      "metadata": {
        "id": "5HwwypzPuHGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Make predictions with trained model\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
        "    # Send data and targets to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # Do the forward pass\n",
        "    y_logit = model_2(X)\n",
        "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
        "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 32, so can perform on dim=1)\n",
        "    # Put predictions on CPU for evaluation\n",
        "    y_preds.append(y_pred.cpu())\n",
        "# Concatenate list of predictions into a tensor\n",
        "y_pred_tensor = torch.cat(y_preds)\n"
      ],
      "metadata": {
        "id": "E4SGzADqxveG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tensor.shape"
      ],
      "metadata": {
        "id": "TYRBPhLByCmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"torchmetrics version : {torchmetrics.__version__}\")\n",
        "  print(f\"mlxtend version : {mlxtend.__version__}\")\n",
        "except:\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"torchmetrics version : {torchmetrics.__version__}\")\n",
        "  print(f\"mlxtend version : {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "b0zfka1GyNi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# 2. Setup confusion instance and compare predictions to targets\n",
        "confmat = ConfusionMatrix(task = 'multiclass', num_classes = len(class_names))\n",
        "confmat_tensor = confmat(preds = y_pred_tensor,\n",
        "                         target = test_data.targets)\n",
        "\n",
        "confmat_tensor"
      ],
      "metadata": {
        "id": "dzO-W63NxEd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Plot the confusion matrix\n",
        "fig,ax = plot_confusion_matrix(\n",
        "    conf_mat = confmat_tensor.numpy(),\n",
        "    class_names=class_names,\n",
        "    figsize = (10,7)\n",
        ")"
      ],
      "metadata": {
        "id": "Bz6UShkA4wDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Save and load best performing model"
      ],
      "metadata": {
        "id": "2wX3Yy_T8Eaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "# Create model Directory path\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents = True, exist_ok= True)\n",
        "\n",
        "# Create model save\n",
        "MODEL_NAME = \"03_pytorch_computer_vision_model_2.pt\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Save the model state dict\n",
        "print(f\"Saving model to : {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj = model_2.state_dict(),\n",
        "           f = MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "TUyRxZH77FjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new instance\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2 = FashionMNISTModelV2(input_shape = 1,\n",
        "                                     hidden_units = 10,\n",
        "                                     output_shape = 10)\n",
        "\n",
        "# Load in the save state_dict()\n",
        "loaded_model_2.load_state_dict(torch.load(f = MODEL_SAVE_PATH))\n",
        "\n",
        "# Send model to target device\n",
        "loaded_model_2.to(device)"
      ],
      "metadata": {
        "id": "qnBJWn3x80sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2_results = eval_model(model = loaded_model_2,\n",
        "                                    data_loader = test_dataloader,\n",
        "                                    loss_fn = loss_fn,\n",
        "                                    accuracy_fn = accuracy_fn)"
      ],
      "metadata": {
        "id": "EkdIKKvj-PzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_2_results"
      ],
      "metadata": {
        "id": "ElYf_B7x-uLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "sKRKeUjQ-xIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the model results are close to each other\n",
        "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
        "               torch.tensor(loaded_model_2_results[\"model_loss\"]),\n",
        "              atol = 1e-01)"
      ],
      "metadata": {
        "id": "dgs8NBxT-0eA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}